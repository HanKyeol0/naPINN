seed: 40
device: "cuda"            # "cuda" or "cpu"
train:
  epochs: 40000
  batch:
    n_f: 8192             # collocation points
    n_b: 1024             # boundary points
    n_0: 1024             # initial points (if applicable)
  optimizer:
    name: adam
    lr: 1.0e-3
  early_stopping:
    enabled: false
    patience: 20000
    min_delta: 1.0e-5
  loss_weights:
    res: 1.0    # PDE residual
    bc: 10.0   # boundary
    ic: 10.0  # initial
    data: 1.0  # data loss
  loss_balancer:
    use_loss_balancer: false
    kind: dwa        # one of: none | uncertainty | dwa | softadapt | gradnorm
    terms: [res, data] # bc, ic
    # DWA:
    T: 2.0
    # SoftAdapt:
    beta: 10.0
    ewma_alpha: 0.7
    # Uncertainty:
    init_log_sigma: 0.0
    # GradNorm-Lite:
    alpha: 0.12
    gamma: 0.5
    update_every: 10
    # If you want a specific layer for GradNorm-Lite (string match in param name):
    # ref_layer_name: "layers.-1.weight"
log:
  out_dir: "outputs"
  wandb:
    enabled: true
    project: "naPINN_NS_test"
    entity: null      # or your team
    mode: "online"      # "auto" | "offline" | "disabled"
eval:
  grid:
    nx: 120
    ny: 120
    nt: 80
  every: 1000